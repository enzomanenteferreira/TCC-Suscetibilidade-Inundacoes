{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d89fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar biliotecas\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f503f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Caminhos \n",
    "path_raster = \"raster_empilhado.tif\"\n",
    "path_modelo = \"modelo_inundacao_RF.pkl\"\n",
    "path_scaler = \"scaler_inundacao.pkl\" \n",
    "output_map = \"mapa_suscetibilidade_inundacao.tif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c91c7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando modelo e scaler...\n",
      " Modelo carregado: modelo_inundacao_RF.pkl\n",
      " Scaler carregado: scaler_inundacao.pkl\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo treinado E O SCALER \n",
    "print(\"\\nCarregando modelo e scaler...\")\n",
    "rf = joblib.load(path_modelo)\n",
    "scaler = joblib.load(path_scaler)  \n",
    "print(\" Modelo carregado: modelo_inundacao_RF.pkl\")\n",
    "print(\" Scaler carregado: scaler_inundacao.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59e2fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lendo raster empilhado...\n"
     ]
    }
   ],
   "source": [
    "# Abrir raster empilhado\n",
    "print(\"\\nLendo raster empilhado...\")\n",
    "with rasterio.open(path_raster) as src:\n",
    "    data = src.read().astype(\"float32\")  \n",
    "    profile = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9e1c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raster lido: 15 bandas, 1798x1079 pixels\n",
      " Total de pixels: 1,940,042\n"
     ]
    }
   ],
   "source": [
    "# Converter raster em tabela (pixels x bandas) \n",
    "bands, rows, cols = data.shape\n",
    "print(f\" Raster lido: {bands} bandas, {rows}x{cols} pixels\")\n",
    "print(f\" Total de pixels: {rows * cols:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d156e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizar dados para (n_pixels, n_bandas)\n",
    "X = data.reshape(bands, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d677836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando pixels v√°lidos...\n",
      "Pixels v√°lidos: 675,192 / 1,940,042\n",
      "Pixels com NaN removidos: 1,264,850\n"
     ]
    }
   ],
   "source": [
    "# === Limpar e tratar NaN ===\n",
    "print(\"\\nProcessando pixels v√°lidos...\")\n",
    "mask_nan = np.any(np.isnan(X), axis=1)\n",
    "X_valid = X[~mask_nan]\n",
    "\n",
    "print(f\"Pixels v√°lidos: {len(X_valid):,} / {len(X):,}\")\n",
    "print(f\"Pixels com NaN removidos: {np.sum(mask_nan):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c2dff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando dados para predi√ß√£o...\n"
     ]
    }
   ],
   "source": [
    "#  Converter para DataFrame\n",
    "print(\"\\nPreparando dados para predi√ß√£o...\")\n",
    "X_df = pd.DataFrame(X_valid, columns=[\n",
    "    # √çndices espectrais\n",
    "    'NDVI', 'NDWI', 'NDBI', 'MNDWI', 'SAVI', 'BSI',\n",
    "\n",
    "    # Vari√°veis topogr√°ficas e hidrol√≥gicas (ordem real no raster)\n",
    "    'TWI',\n",
    "    'Altitude', 'Curvatura_H', 'Curvatura_V', 'Declividade',\n",
    "    'Divisores', 'Forma_terreno', 'Orientacao', 'Relevo'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0910f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando normaliza√ß√£o (StandardScaler)\n",
      " Dados normalizados\n"
     ]
    }
   ],
   "source": [
    "# aplicar a normalizacao com o mesmo scaler do treino\n",
    "print(\"Aplicando normaliza√ß√£o (StandardScaler)\")\n",
    "X_df_scaled = scaler.transform(X_df)\n",
    "X_df = pd.DataFrame(X_df_scaled, columns=X_df.columns)\n",
    "print(\" Dados normalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c49e60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Processando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:03<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Previs√µes conclu√≠das\n",
      " Probabilidade m√©dia: 0.3986\n",
      " Probabilidade m√≠n: 0.0326\n",
      " Probabilidade m√°x: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predizer em lotes \n",
    "batch_size = 50000\n",
    "y_pred_prob = np.zeros(len(X_df), dtype='float32')\n",
    "\n",
    "for i in tqdm(range(0, len(X_df), batch_size), desc=\"   Processando\"):\n",
    "    end_idx = min(i + batch_size, len(X_df))\n",
    "    y_pred_prob[i:end_idx] = rf.predict_proba(X_df.iloc[i:end_idx])[:, 1]\n",
    "\n",
    "print(f\" Previs√µes conclu√≠das\")\n",
    "print(f\" Probabilidade m√©dia: {y_pred_prob.mean():.4f}\")\n",
    "print(f\" Probabilidade m√≠n: {y_pred_prob.min():.4f}\")\n",
    "print(f\" Probabilidade m√°x: {y_pred_prob.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "516fb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reconstruindo imagem espacial...\n"
     ]
    }
   ],
   "source": [
    "# Criar array final com NaN onde faltou dado \n",
    "print(\"\\n Reconstruindo imagem espacial...\")\n",
    "pred_full = np.full(X.shape[0], np.nan, dtype=\"float32\")\n",
    "pred_full[~mask_nan] = y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17dbd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voltar ao formato espacial (rows, cols)\n",
    "mapa_pred = pred_full.reshape(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8086325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar perfil para 1 banda \n",
    "profile.update(count=1, dtype=\"float32\", nodata=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86464e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando mapa...\n"
     ]
    }
   ],
   "source": [
    "# Salvar GeoTIFF\n",
    "print(\"\\nSalvando mapa...\")\n",
    "with rasterio.open(output_map, \"w\", **profile) as dst:\n",
    "    dst.write(mapa_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e168d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ESTAT√çSTICAS DO MAPA GERADO\n",
      "============================================================\n",
      "Dimens√µes: 1798 x 1079 pixels\n",
      "Pixels classificados: 675,192\n",
      "Pixels com alta suscetibilidade (>0.7): 102,258\n",
      "Pixels com m√©dia suscetibilidade (0.3-0.7): 275,568\n",
      "Pixels com baixa suscetibilidade (<0.3): 297,366\n",
      "============================================================\n",
      "‚úì Processamento conclu√≠do com sucesso!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Estat√≠sticas finais\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ESTAT√çSTICAS DO MAPA GERADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dimens√µes: {rows} x {cols} pixels\")\n",
    "print(f\"Pixels classificados: {(~np.isnan(mapa_pred)).sum():,}\")\n",
    "print(f\"Pixels com alta suscetibilidade (>0.7): {(mapa_pred > 0.7).sum():,}\")\n",
    "print(f\"Pixels com m√©dia suscetibilidade (0.3-0.7): {((mapa_pred >= 0.3) & (mapa_pred <= 0.7)).sum():,}\")\n",
    "print(f\"Pixels com baixa suscetibilidade (<0.3): {(mapa_pred < 0.3).sum():,}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úì Processamento conclu√≠do com sucesso!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GERA√á√ÉO DO MAPA DE SUSCETIBILIDADE √Ä INUNDA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === Caminhos ===\n",
    "path_raster = \"raster_empilhado.tif\"\n",
    "path_modelo = \"modelo_inundacao_RF.pkl\"\n",
    "path_scaler = \"scaler_inundacao.pkl\"  \n",
    "output_map = \"mapa_suscetibilidade_inundacao.tif\"\n",
    "\n",
    "# === Carregar modelo treinado E O SCALER ===\n",
    "print(\"\\n Carregando modelo e scaler...\")\n",
    "rf = joblib.load(path_modelo)\n",
    "scaler = joblib.load(path_scaler)  \n",
    "print(\"   ‚úì Modelo carregado: modelo_inundacao_RF.pkl\")\n",
    "print(\"   ‚úì Scaler carregado: scaler_inundacao.pkl\")\n",
    "\n",
    "# === Abrir raster empilhado ===\n",
    "print(\"\\n Lendo raster empilhado...\")\n",
    "with rasterio.open(path_raster) as src:\n",
    "    data = src.read().astype(\"float32\")  # shape: (bands, rows, cols)\n",
    "    profile = src.profile\n",
    "\n",
    "# === Converter raster em tabela (pixels x bandas) ===\n",
    "bands, rows, cols = data.shape\n",
    "print(f\"  Raster lido: {bands} bandas, {rows}x{cols} pixels\")\n",
    "print(f\"  Total de pixels: {rows * cols:,}\")\n",
    "\n",
    "# Reorganizar dados para (n_pixels, n_bandas)\n",
    "X = data.reshape(bands, -1).T\n",
    "\n",
    "# === Limpar e tratar NaN ===\n",
    "print(\"\\nProcessando pixels v√°lidos...\")\n",
    "mask_nan = np.any(np.isnan(X), axis=1)\n",
    "X_valid = X[~mask_nan]\n",
    "\n",
    "print(f\"   ‚úì Pixels v√°lidos: {len(X_valid):,} / {len(X):,}\")\n",
    "print(f\"   ‚úì Pixels com NaN removidos: {np.sum(mask_nan):,}\")\n",
    "\n",
    "# === Converter para DataFrame ===\n",
    "print(\"\\n Preparando dados para predi√ß√£o...\")\n",
    "X_df = pd.DataFrame(X_valid, columns=[\n",
    "    'NDVI', 'NDWI', 'NDBI', 'MNDWI', 'SAVI', 'BSI',\n",
    "    'Altitude', 'Curvatura_H', 'Curvatura_V', 'Declividade',\n",
    "    'Forma_Terreno', 'Relevo', 'Orientacao', 'Divisores'\n",
    "])\n",
    "\n",
    "#  APLICAR A NORMALIZA√á√ÉO COM O MESMO SCALER DO TREINO\n",
    "print(\"  Aplicando normaliza√ß√£o (StandardScaler)...\")\n",
    "X_df_scaled = scaler.transform(X_df)  # üî• CR√çTICO: usar transform, n√£o fit_transform\n",
    "X_df = pd.DataFrame(X_df_scaled, columns=X_df.columns)\n",
    "print(\"   ‚úì Dados normalizados\")\n",
    "\n",
    "# === Prever probabilidade de inunda√ß√£o ===\n",
    "print(\"\\nGerando previs√µes...\")\n",
    "print(\"   (Isso pode levar alguns minutos...)\")\n",
    "\n",
    "# Predizer em lotes para economizar mem√≥ria (opcional, mas recomendado)\n",
    "batch_size = 50000\n",
    "y_pred_prob = np.zeros(len(X_df), dtype='float32')\n",
    "\n",
    "for i in tqdm(range(0, len(X_df), batch_size), desc=\"   Processando\"):\n",
    "    end_idx = min(i + batch_size, len(X_df))\n",
    "    y_pred_prob[i:end_idx] = rf.predict_proba(X_df.iloc[i:end_idx])[:, 1]\n",
    "\n",
    "print(f\"   ‚úì Previs√µes conclu√≠das\")\n",
    "print(f\"   ‚úì Probabilidade m√©dia: {y_pred_prob.mean():.4f}\")\n",
    "print(f\"   ‚úì Probabilidade m√≠n: {y_pred_prob.min():.4f}\")\n",
    "print(f\"   ‚úì Probabilidade m√°x: {y_pred_prob.max():.4f}\")\n",
    "\n",
    "# === Criar array final com NaN onde faltou dado ===\n",
    "print(\"\\n Reconstruindo imagem espacial...\")\n",
    "pred_full = np.full(X.shape[0], np.nan, dtype=\"float32\")\n",
    "pred_full[~mask_nan] = y_pred_prob\n",
    "\n",
    "# Voltar ao formato espacial (rows, cols)\n",
    "mapa_pred = pred_full.reshape(rows, cols)\n",
    "\n",
    "# === Atualizar perfil para 1 banda ===\n",
    "profile.update(count=1, dtype=\"float32\", nodata=np.nan)\n",
    "\n",
    "# === Salvar GeoTIFF ===\n",
    "print(\"\\nSalvando mapa...\")\n",
    "with rasterio.open(output_map, \"w\", **profile) as dst:\n",
    "    dst.write(mapa_pred, 1)\n",
    "\n",
    "print(f\"   ‚úì Mapa salvo: {output_map}\")\n",
    "\n",
    "# === Estat√≠sticas finais ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ESTAT√çSTICAS DO MAPA GERADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dimens√µes: {rows} x {cols} pixels\")\n",
    "print(f\"Pixels classificados: {(~np.isnan(mapa_pred)).sum():,}\")\n",
    "print(f\"Pixels com alta suscetibilidade (>0.7): {(mapa_pred > 0.7).sum():,}\")\n",
    "print(f\"Pixels com m√©dia suscetibilidade (0.3-0.7): {((mapa_pred >= 0.3) & (mapa_pred <= 0.7)).sum():,}\")\n",
    "print(f\"Pixels com baixa suscetibilidade (<0.3): {(mapa_pred < 0.3).sum():,}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úì Processamento conclu√≠do com sucesso!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
